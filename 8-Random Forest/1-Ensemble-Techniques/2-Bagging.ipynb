{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec71f93",
   "metadata": {},
   "source": [
    "### ðŸŸ¦ Bagging (Bootstrap Aggregating)\n",
    "\n",
    "**Think of the process like this:**\n",
    "\n",
    "1. **Start with your dataset**\n",
    "   Say you have 1000 rows of data about houses (features: size, location, number of rooms â†’ target: price).\n",
    "\n",
    "2. **Create random samples**\n",
    "   Bagging makes many new datasets by randomly picking rows from the original dataset (some rows may repeat, some may be left out).\n",
    "\n",
    "3. **Train multiple models**\n",
    "   On each random dataset, train the same type of model â€” for example, decision trees.\n",
    "\n",
    "   * Tree 1 learns one pattern.\n",
    "   * Tree 2 learns slightly differently because it saw a different dataset.\n",
    "   * Tree 3 learns something else.\n",
    "\n",
    "4. **Combine predictions**\n",
    "   When you want to predict the price of a new house:\n",
    "\n",
    "   * Each tree gives its own prediction.\n",
    "   * Final result = **average of all treesâ€™ predictions**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”‘ In ML terms:\n",
    "\n",
    "* Bagging = **training models in parallel on different random subsets**.\n",
    "* Final prediction = **aggregate (average or vote)** of all models.\n",
    "* Benefit = reduces **variance** (less chance of overfitting).\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Small Example:**\n",
    "Predicting house price for a new home:\n",
    "\n",
    "* Tree 1 â†’ \\$200k\n",
    "* Tree 2 â†’ \\$220k\n",
    "* Tree 3 â†’ \\$210k\n",
    "  **Final Bagging prediction = (200 + 220 + 210) / 3 = \\$210k**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
