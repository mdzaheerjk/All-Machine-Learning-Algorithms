{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894b6dfd",
   "metadata": {},
   "source": [
    "# Ada-Boost Regreesion with two weak learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5950c0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 🏠 House Price Example (AdaBoost Regressor)\n",
    "\n",
    "We want to predict house prices.  \n",
    "The real prices are:\n",
    "\n",
    "```\n",
    "House   True Price\n",
    "A       200\n",
    "B       300\n",
    "C       400\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 1: Weak Learner 1 (the rough guess)\n",
    "\n",
    "Imagine our first weak learner is very simple: it just predicts the **average price** for all houses.\n",
    "\n",
    "- Average = (200 + 300 + 400) / 3 = **300**  \n",
    "\n",
    "So predictions are:\n",
    "\n",
    "```\n",
    "A: 300   (but true is 200 → error = -100)\n",
    "B: 300   (true is 300 → error = 0)\n",
    "C: 300   (true is 400 → error = +100)\n",
    "```\n",
    "\n",
    "👉 Weak Learner 1 is too simple. It gets B right but misses A and C.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 2: Focus on the Errors\n",
    "\n",
    "AdaBoost says: \"Okay, Learner 1 made big mistakes for A and C. Let’s train another weak learner to correct those errors.\"\n",
    "\n",
    "So, **Weak Learner 2** tries to predict the **correction (residual)**:\n",
    "\n",
    "```\n",
    "A needs -100 correction\n",
    "B needs   0 correction\n",
    "C needs +100 correction\n",
    "```\n",
    "\n",
    "Learner 2 learns something close to these corrections.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 3: Combine Them\n",
    "\n",
    "Now we combine the two learners.  \n",
    "The final prediction is:\n",
    "\n",
    "```\n",
    "Final Prediction = Learner 1’s guess + Learner 2’s correction\n",
    "```\n",
    "\n",
    "So:\n",
    "\n",
    "```\n",
    "A: 300 + (-100) = 200 ✅\n",
    "B: 300 + 0      = 300 ✅\n",
    "C: 300 + (+100) = 400 ✅\n",
    "```\n",
    "\n",
    "👉 Perfect results after just 2 weak learners.\n",
    "\n",
    "---\n",
    "\n",
    "## 🌟 Key Takeaway\n",
    "\n",
    "- **Learner 1**: makes a rough overall guess (average).  \n",
    "- **Learner 2**: fixes the mistakes from Learner 1 (adds corrections).  \n",
    "- **Together**: they become accurate.  \n",
    "\n",
    "AdaBoost repeats this idea with many learners:\n",
    "👉 *first guess → find mistakes → correct them → combine everything*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04f525",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Ada-Boost Regreesion with three weak learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2b7e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 🏠 House Price Example with 3 Learners\n",
    "\n",
    "True prices:\n",
    "\n",
    "```\n",
    "House   True Price\n",
    "A       200\n",
    "B       300\n",
    "C       400\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 1: Weak Learner 1 (the rough guess)\n",
    "\n",
    "Learner 1 predicts the **average of all houses**:\n",
    "\n",
    "* Average = (200 + 300 + 400) / 3 = **300**\n",
    "\n",
    "Predictions:\n",
    "\n",
    "```\n",
    "A: 300   (error = -100)\n",
    "B: 300   (error =   0)\n",
    "C: 300   (error = +100)\n",
    "```\n",
    "\n",
    "👉 Good for B, but bad for A and C.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 2: Weak Learner 2 (fixes mistakes)\n",
    "\n",
    "Learner 2 tries to predict the **corrections (residuals)** from Learner 1:\n",
    "\n",
    "```\n",
    "A needs -100\n",
    "B needs   0\n",
    "C needs +100\n",
    "```\n",
    "\n",
    "Suppose Learner 2 is weak and doesn’t perfectly predict — it only predicts **half of the needed correction**:\n",
    "\n",
    "```\n",
    "A: -50\n",
    "B:   0\n",
    "C: +50\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 3: Combine Learner 1 + Learner 2\n",
    "\n",
    "Final after 2 learners:\n",
    "\n",
    "```\n",
    "A: 300 + (-50) = 250   (still too high, error = -50)\n",
    "B: 300 +   0   = 300   (perfect ✅)\n",
    "C: 300 +  50   = 350   (still too low, error = +50)\n",
    "```\n",
    "\n",
    "👉 Better than before, but not perfect yet.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 4: Weak Learner 3 (fixes what’s still wrong)\n",
    "\n",
    "Now AdaBoost looks at the remaining errors:\n",
    "\n",
    "```\n",
    "A needs -50 more\n",
    "B needs  0\n",
    "C needs +50 more\n",
    "```\n",
    "\n",
    "Learner 3 again only predicts half the correction:\n",
    "\n",
    "```\n",
    "A: -25\n",
    "B:   0\n",
    "C: +25\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Step 5: Combine All 3 Learners\n",
    "\n",
    "Final predictions:\n",
    "\n",
    "```\n",
    "A: 300 + (-50) + (-25) = 225   (error = -25)\n",
    "B: 300 +  0   +   0    = 300   (perfect ✅)\n",
    "C: 300 +  50  +  25    = 375   (error = +25)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🌟 Key Takeaway\n",
    "\n",
    "* **Learner 1**: gives a rough starting point (300 for all).\n",
    "* **Learner 2**: moves the predictions closer (fixes half the error).\n",
    "* **Learner 3**: fixes a bit more.\n",
    "* If we keep adding learners, we get closer and closer to the true values.\n",
    "\n",
    "👉 That’s how AdaBoost builds a **strong regressor** out of many weak learners:\n",
    "**guess → correct → correct more → … until accurate.**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
