{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ca8e3e",
   "metadata": {},
   "source": [
    "# Types of Cross validations\n",
    "\n",
    "## ğŸ”¹ 1. Leave-One-Out Cross Validation (LOOCV)\n",
    "\n",
    "ğŸ‘‰ Imagine you have **10 questions**.\n",
    "\n",
    "* Train the model on 9 questions, test it on the **1 question left out**.\n",
    "* Repeat this 10 times, each time leaving out a different question.\n",
    "* Average the results.\n",
    "\n",
    "âœ… Very thorough (uses almost all data for training).\n",
    "âŒ But can be slow if you have a lot of data, because it repeats many times.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 2. Leave-P-Out Cross Validation\n",
    "\n",
    "ğŸ‘‰ Similar to LOOCV, but instead of leaving **1 question out**, you leave out **P questions** at a time.\n",
    "\n",
    "* Example: With 10 questions, leave out 2 each time.\n",
    "* Train on 8, test on 2 â†’ repeat for all possible combinations.\n",
    "\n",
    "âœ… More flexible than LOOCV.\n",
    "âŒ Gets very expensive if P is big or dataset is large.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 3. K-Fold Cross Validation\n",
    "\n",
    "ğŸ‘‰ The most common one.\n",
    "\n",
    "* Split your data into **k equal groups** (say 5 groups).\n",
    "* Train on 4 groups, test on the 1 left out.\n",
    "* Repeat until every group has been tested once.\n",
    "* Average the results.\n",
    "\n",
    "âœ… Balanced, efficient, widely used.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 4. Stratified K-Fold Cross Validation\n",
    "\n",
    "ğŸ‘‰ Same as K-Fold, but with a twist:\n",
    "\n",
    "* Useful when your data has **categories** (like 70% cats, 30% dogs).\n",
    "* It makes sure **each fold keeps the same ratio** of cats and dogs.\n",
    "* This prevents some folds from being â€œunbalancedâ€ (e.g., one fold with mostly cats).\n",
    "\n",
    "âœ… Best for classification problems.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 5. Time Series Cross Validation\n",
    "\n",
    "ğŸ‘‰ Special for **time-based data** (like stock prices, weather, sales).\n",
    "\n",
    "* You canâ€™t shuffle time, because the past always comes before the future.\n",
    "* Instead, you train on earlier data and test on later data.\n",
    "* Example:\n",
    "\n",
    "  * Train on Janâ€“Mar, test on Apr\n",
    "  * Train on Janâ€“Apr, test on May\n",
    "  * Train on Janâ€“May, test on Jun\n",
    "\n",
    "âœ… Respects the order of time.\n",
    "âŒ Canâ€™t randomly split like K-Fold.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… In short:\n",
    "\n",
    "* **LOOCV** â†’ leave 1 out each time.\n",
    "* **Leave-P-Out** â†’ leave P out each time.\n",
    "* **K-Fold** â†’ split into k groups.\n",
    "* **Stratified K-Fold** â†’ like K-Fold but keeps category balance.\n",
    "* **Time Series CV** â†’ train on past, test on future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f7660e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Imagine youâ€™re training a model\n",
    "\n",
    "## You have 100 practice questions/samples (your training data).\n",
    "\n",
    "## You want to know if the model is really learning, not just memorizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb8314c",
   "metadata": {},
   "source": [
    "### Option 1: One Train-Test Split\n",
    "\n",
    "* **Training data (80 questions)** â†’ like giving the model **80 samples** to learn from.\n",
    "* **Test data (20 questions)** â†’ like holding out **20 samples** to check performance.\n",
    "\n",
    "**Problem**: The model is only evaluated on that **one specific test set**.\n",
    "\n",
    "* If those 20 samples are unusually easy/hard, the performance estimate may be **biased** or **lucky**.\n",
    "\n",
    "---\n",
    "\n",
    "### Option 2: Cross-Validation (CV)\n",
    "\n",
    "1. **Split the dataset into 5 folds** (20 samples per fold).\n",
    "2. **Round 1:** Train on 4 folds (80 samples), test on 1 fold (20 samples).\n",
    "3. **Round 2:** Train on a different 4 folds, test on the next fold.\n",
    "4. Repeat until **every fold has been the test set once**.\n",
    "\n",
    "Now you have **5 evaluation scores**, one per fold.\n",
    "ğŸ‘‰ Take the **average** to estimate performance.\n",
    "\n",
    "---\n",
    "\n",
    "### Why CV is Better (in ML terms)\n",
    "\n",
    "âœ… **Every data point** is used for **training** and for **testing** â†’ no wasted data.\n",
    "âœ… The model is tested on **multiple splits**, reducing bias from a single lucky/unlucky test set.\n",
    "âœ… Produces a **more stable and reliable estimate** of model performance (generalization ability).\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‘‰ Thatâ€™s why in ML, cross-validation is the standard way to check if a model is **learning true patterns** in the data rather than just **memorizing a single train-test split**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b4be7e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "### ğŸ”¹ How Tuning Works in Machine Learning\n",
    "\n",
    "1. You pick some **values to try** for each hyperparameter.\n",
    "\n",
    "   * Example: alpha = [0.1, 1, 10]\n",
    "2. For each combination:\n",
    "\n",
    "   * Train the model on part of your data.\n",
    "   * Test it on another part (cross-validation).\n",
    "   * Measure performance.\n",
    "3. Choose the hyperparameter values that **give the best results**.\n",
    "4. Retrain the model on all training data using these best values.\n",
    "\n",
    "\n",
    "### ğŸ”¹ Key Point\n",
    "\n",
    "* **Hyperparameters are not learned** from data; you set them.\n",
    "* Tuning is **testing different settings** to find the ones that work best.\n",
    "* Cross-validation is often used to **check each setting fairly**.\n",
    "\n",
    "\n",
    "âœ… In one line:\n",
    "Hyperparameter tuning = trying different â€œsettingsâ€ for your model to make it perform as well as possible on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1953c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Most Commonly used hyperparameter tuning techniques\n",
    "\n",
    "### ğŸ”¹ 1. Grid Search\n",
    "\n",
    "* **How it works:** You make a **list of possible values** for each hyperparameter.\n",
    "* The algorithm tries **every possible combination** and checks which one works best.\n",
    "* **Pros:** Simple, guarantees you test all combinations.\n",
    "* **Cons:** Can be very slow if you have many hyperparameters or many values.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "alpha = [0.1, 1, 10]\n",
    "max_depth = [3, 5, 7]\n",
    "# Grid Search will try all 3 x 3 = 9 combinations\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ 2. Random Search\n",
    "\n",
    "* **How it works:** Instead of trying all combinations, it **randomly picks some combinations** to test.\n",
    "* **Pros:** Much faster than grid search for large search spaces.\n",
    "* **Cons:** Might miss the best combination.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "alpha = [0.1, 1, 10, 100]\n",
    "Randomly pick 2 or 3 combinations to try instead of all 4.\n",
    "```\n",
    "\n",
    "\n",
    "### ğŸ”¹3. LassoCV / RidgeCV / Tree-based CV\n",
    "\n",
    "* Some models, like **LassoCV**, automatically **tune certain hyperparameters** (like `alpha`) using cross-validation.\n",
    "* **Pros:** Easy to use, no manual search needed.\n",
    "* **Cons:** Only works for specific parameters/models.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Summary Table (Simple)**\n",
    "\n",
    "| Technique             | Pros                     | Cons                      |\n",
    "| --------------------- | ------------------------ | ------------------------- |\n",
    "| Grid Search           | Tries all combos, simple | Slow for big search space |\n",
    "| Random Search         | Faster                   | Might miss best values    |\n",
    "| CV-based tuning       | Automatic, easy          | Limited to some models    |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
